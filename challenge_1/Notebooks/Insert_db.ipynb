{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from typing import Optional, Tuple\n",
    "import re\n",
    "\n",
    "def connect_db(user: str, password: str, host: str, port: str, db_name: str) -> Tuple:\n",
    "    \"\"\"Conexión a la base de datos\n",
    "\n",
    "    Args:\n",
    "        user (str): usuario de la base de datos\n",
    "        password (str): contraseña del usuario\n",
    "        host (str): dirección IP o hostname del servidor de la base de datos\n",
    "        port (str): puerto del servidor de la base de datos\n",
    "        db_name (str): nombre de la base de datos a la que conectarse\n",
    "\n",
    "    Returns:\n",
    "        Tuple: devuelve dos objetos para manejar la conexión con la base de datos:\n",
    "            sql_engine (sqlalchemy.engine.base.Engine): objeto para utilizarlo como conexión y así, guardar información a la base de datos\n",
    "            db_connection (sqlalchemy.engine.base.Connection): objeto para utilizarlo como conexión y así, leer información de la base datos\n",
    "    \"\"\"\n",
    "    try:\n",
    "        db_url = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "        sql_engine = create_engine(db_url)\n",
    "        db_connection = sql_engine.connect()\n",
    "        print(f\"Connected to database {db_name} as user {user}\")\n",
    "    except Exception as e:\n",
    "        sql_engine = None\n",
    "        db_connection = None\n",
    "        print(f\"Failed to connect to database {db_name} as user {user}: {e}\")\n",
    "    return sql_engine, db_connection\n",
    "\n",
    "def get_csv_files(path: str, pattern: str) -> list:\n",
    "    \"\"\"Obtiene los archivos CSV del directorio especificado que cumplen el patrón especificado.\n",
    "\n",
    "    Args:\n",
    "        path (str): directorio donde buscar los archivos\n",
    "        pattern (str): patrón para buscar los archivos\n",
    "\n",
    "    Returns:\n",
    "        list: lista de archivos CSV que cumplen el patrón\n",
    "    \"\"\"\n",
    "    csv_files = sorted(glob.glob(f\"{path}/{pattern}\"))\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "\n",
    "def get_name_files(path_csv_files):\n",
    "    \"\"\"Obtiene el nombre de la tabla de la base de datos a partir del nombre del archivo CSV.\n",
    "\n",
    "    Args:\n",
    "        path_csv_files (str): ruta del archivo CSV\n",
    "\n",
    "    Returns:\n",
    "        str: nombre de la tabla de la base de datos\n",
    "    \"\"\"\n",
    "    #Get filename in csv_files\n",
    "    table_name=[]\n",
    "    for file in path_csv_files:\n",
    "        match = re.search(r'\\\\([^\\\\]+)\\.', file)\n",
    "        if match:\n",
    "            filename = match.group(1)\n",
    "            # Nombre que queda en la tabla de base de  datos\n",
    "            table_name.append(filename)\n",
    "    return table_name\n",
    "\n",
    "\n",
    "\n",
    "def insert_csv_to_db(microbatch: int,path_csv_files: str,sql_engine: object, table_name:str)-> None:\n",
    "\n",
    "    \"\"\"Inserta los datos del archivo CSV en la tabla correspondiente de la base de datos.\n",
    "\n",
    "    Args:\n",
    "        csv_files (List): ruta de cada archivo CSV\n",
    "        table_name (str): nombre de la tabla de la base de datos\n",
    "        microbatch (int): tamaño de los bloques en los que se insertarán los datos\n",
    "        sql_engine (sqlalchemy.engine.base.Engine): Sirve para utilizarlo como conexion y asi, guardar informacion a la base de datos\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "        \n",
    "    column_names = [\n",
    "        # Sublista para la tabla \"departments\"\n",
    "        [\"id\", \"department\"],\n",
    "        # Sublista para la tabla \"hired_employees\"\n",
    "        [\"id\", \"name\", \"datetime\", \"department_id\", \"job_id\"],\n",
    "        # Sublista para la tabla \"jobs\"\n",
    "        [\"id\", \"job\"]\n",
    "         ]\n",
    "\n",
    "    for i in range(len(path_csv_files)):\n",
    "        for chunk in pd.read_csv(path_csv_files[i], chunksize=microbatch,header=None,names=column_names[i]):\n",
    "            # insercion en base de datos\n",
    "            try:\n",
    "                chunk.to_sql(name=table_name[i], con=sql_engine, if_exists=\"append\",index=None)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to insert rows from {path_csv_files[i]} into table {table_name}: {e}\")\n",
    "                raise e\n",
    "             \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #credentials dataBases for connect_db()\n",
    "    user=\"admin\"\n",
    "    password=\"12345678\"\n",
    "    host=\"mydb.cjt7teobtbru.us-east-1.rds.amazonaws.com\"\n",
    "    port=\"3306\"\n",
    "    db=\"Globant\"\n",
    "\n",
    "    # for get_csv_files()\n",
    "    pattern = \"/*.csv\"\n",
    "    path = \"../files\"\n",
    "\n",
    "    # Cantidad de registros a insertar por iteracion\n",
    "    microbatch = 20\n",
    "\n",
    "\n",
    "    #call connect_db function\n",
    "    sql_engine, db_connection=connect_db(user,password,host,port,db)\n",
    "\n",
    "    #call get_csv_files function\n",
    "    path_csv_files=get_csv_files(path,pattern)\n",
    "\n",
    "    #call get_name_files function\n",
    "    table_name=get_name_files(path_csv_files)\n",
    "\n",
    "    #call insert_db() function\n",
    "    insert_csv_to_db(microbatch,path_csv_files,sql_engine,table_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avro_utils.py\n",
    "import boto3\n",
    "import pymysql\n",
    "import botocore\n",
    "\n",
    "from typing import Optional, Union, Dict\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "aws_access_key_id=credentials.access_key\n",
    "aws_secret_access_key=credentials.secret_key\n",
    "aws_region_name = 'us-east-1'\n",
    "\n",
    "\n",
    "# Acceder a las variables de entorno\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "host = os.getenv(\"host\")\n",
    "port = os.getenv(\"port\")\n",
    "db = os.getenv(\"db\")\n",
    "list_name_table = os.getenv(\"list_name_table\").split(',')\n",
    "s3_bucket_name = os.getenv(\"s3_bucket_name\")\n",
    "s3_prefix = os.getenv(\"s3_prefix\")\n",
    "s3_prefix_backup = os.getenv(\"s3_prefix_backup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jobs,departments,hired_employees'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_name_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "\n",
    "def connect_db(user: str, password: str, host: str, port: str, db_name: str) -> Tuple:\n",
    "    \"\"\"Conexión a la base de datos\n",
    "\n",
    "    Args:\n",
    "        user (str): usuario de la base de datos\n",
    "        password (str): contraseña del usuario\n",
    "        host (str): dirección IP o hostname del servidor de la base de datos\n",
    "        port (str): puerto del servidor de la base de datos\n",
    "        db_name (str): nombre de la base de datos a la que conectarse\n",
    "\n",
    "    Returns:\n",
    "        Tuple: devuelve dos objetos para manejar la conexión con la base de datos:\n",
    "            sql_engine (sqlalchemy.engine.base.Engine): objeto para utilizarlo como conexión y así, guardar información a la base de datos\n",
    "            db_connection (sqlalchemy.engine.base.Connection): objeto para utilizarlo como conexión y así, leer información de la base datos\n",
    "    \"\"\"\n",
    "    try:\n",
    "        db_url = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "        sql_engine = create_engine(db_url)\n",
    "        db_connection = sql_engine.connect()\n",
    "        print(f\"Connected to database {db_name} as user {user}\")\n",
    "    except Exception as e:\n",
    "        sql_engine = None\n",
    "        db_connection = None\n",
    "        print(f\"Failed to connect to database {db_name} as user {user}: {e}\")\n",
    "    return sql_engine, db_connection\n",
    "\n",
    "def insert_db(df,sql_engine):\n",
    "    name_table=\"department_prueba\"\n",
    "    if name_table==\"department_prueba\":\n",
    "        name_colum=[\"id\",\"department\"]\n",
    "    try:\n",
    "        df.columns = name_colum\n",
    "        df.to_sql(name=name_table, con=sql_engine, if_exists=\"append\", index=None)\n",
    "        print(\"Inserting\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to insert rows from {df}.csv into table {name_table}: {e}\")\n",
    "        raise e\n",
    "    # Crea un objeto S3\n",
    "    \n",
    "\n",
    "    # Define el nombre del bucket y el archivo a leer\n",
    "\n",
    "\n",
    "def csv_to_df(csv):\n",
    "    return pd.read_csv(io.StringIO(csv))\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user=\"admin\"\n",
    "password=\"12345678\"\n",
    "host=\"mydb.cjt7teobtbru.us-east-1.rds.amazonaws.com\"\n",
    "port=\"3306\"\n",
    "db=\"Globant\"\n",
    "\n",
    "csv='''id,department\n",
    "1,Marketing\n",
    "2,Finance\n",
    "3,Human Resources\n",
    "4,IT\n",
    "5,Operations'''\n",
    "\n",
    "sql_engine, db_connection=connect_db(user,password,host,port,db)\n",
    "df=csv_to_df(csv)\n",
    "insert_db(df,sql_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import io\n",
    "\n",
    "\n",
    "def connect_db(user, password, host, database):\n",
    "    try:\n",
    "        # Establecer la conexión con MySQL\n",
    "        cnx = pymysql.connect(user=user, password=password, host=host, database=database)\n",
    "\n",
    "        print(\"Connected to the database\")\n",
    "\n",
    "        return cnx\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to the database: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "\n",
    "def insert_db(cnx,df,table_name):\n",
    "    try:\n",
    "    \n",
    "        # Crear un cursor para ejecutar sentencias SQL\n",
    "        cursor = cnx.cursor()\n",
    "        \n",
    "        # Verificar si la tabla existe, y crearla si no existe\n",
    "        query = f\"CREATE TABLE IF NOT EXISTS {table_name} (id INT PRIMARY KEY, department TEXT)\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Preparar la sentencia SQL para insertar los datos del DataFrame en la tabla de MySQL\n",
    "        cols = \",\".join([str(i) for i in df.columns.tolist()])\n",
    "        values = \"),(\".join([\", \".join([f\"'{str(x)}'\" for x in i]) for i in df.values.tolist()])\n",
    "        query = f\"INSERT INTO {table_name} ({cols}) VALUES ({values})\"\n",
    "        \n",
    "        # Ejecutar la sentencia SQL\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Hacer commit para confirmar los cambios en la base de datos\n",
    "        cnx.commit()\n",
    "        \n",
    "        print(\"Inserting\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to insert rows from {df} into table {table_name}: {e}\")\n",
    "        raise e\n",
    "        \n",
    "    finally:\n",
    "        # Cerrar la conexión y liberar los recursos\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "def csv_to_df(csv):\n",
    "    return pd.read_csv(io.StringIO(csv))\n",
    "\n",
    "\n",
    "\n",
    "user=\"admin\"\n",
    "password=\"12345678\"\n",
    "host=\"mydb.cjt7teobtbru.us-east-1.rds.amazonaws.com\"\n",
    "port=\"3306\"\n",
    "db=\"Globant\"\n",
    "\n",
    "csv='''id,department\n",
    "1,Marketing\n",
    "2,Finance\n",
    "3,Human Resources\n",
    "4,IT\n",
    "5,Operations'''\n",
    "\n",
    "table_name=\"departments\"\n",
    "cnx=connect_db(user, password, host, db)\n",
    "df=csv_to_df(csv)\n",
    "insert_db(cnx,df,table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"admin\"\n",
    "password=\"12345678\"\n",
    "host=\"mydb.cjt7teobtbru.us-east-1.rds.amazonaws.com\"\n",
    "port=\"3306\"\n",
    "db=\"Globant\"\n",
    "\n",
    "csv='''id,department\n",
    "1,Marketing\n",
    "2,Finance\n",
    "3,Human Resources\n",
    "4,IT\n",
    "5,Operations'''\n",
    "\n",
    "table_name=\"depart_test\"\n",
    "cnx=connect_db(user, password, host, db)\n",
    "df=csv_to_df(csv)\n",
    "insert_db(cnx,df,table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data={\n",
    " \"id\": [111, 211, 311, 411, 511],\n",
    " \"job\": [\"Software Engineer\", \"Data Scientist\", \"Backend\", \"Gerente\", \"Operations\"]\n",
    "}\n",
    "\n",
    "data='''{\n",
    "  \"id\": [111, 211, 311, 411, 511],\n",
    "  \"name\": [\"Marketing\", \"Finance\", \"Human Resources\", \"IT\", \"Operations\"],\n",
    "  \"datetime\": [\"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\"],\n",
    "  \"department_id\": [11, 22, 33, 41, 52],\n",
    "  \"job_id\": [1, 2, 3, 4, 5]\n",
    "}'''\n",
    "\n",
    "#data=json.dumps(data)\n",
    "data=json.loads(data)\n",
    "gg=pd.DataFrame(data)\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "  \"id\": [111, 211, 311, 411, 511],\n",
    "  \"department\": [\"Marketing\", \"Finance\", \"Human Resources\", \"IT\", \"Operations\"],\n",
    "  \"datetime\": [\"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\", \"2021-11-07T02:48:42Z\"],\n",
    "  \"department_id\": [11, 22, 33, 41, 52,],\n",
    "  \"job_id\": [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "data=json.dumps(data)\n",
    "data=json.loads(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_db(df, user, password, host, \"Globant\", \"Prueba_departmen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
